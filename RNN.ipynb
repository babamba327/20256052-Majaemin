{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fFtofkYGYg7a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1R1528OKYtFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Healthy_train = np.load('/content/drive/MyDrive/DL_Colab/DL_data/Bearing_Healthy_train.npy')\n",
        "InnerFault_train = np.load('/content/drive/MyDrive/DL_Colab/DL_data/Bearing_InnerFault_train.npy')\n",
        "OuterFault_train = np.load('/content/drive/MyDrive/DL_Colab/DL_data/Bearing_OuterFault_train.npy')\n",
        "\n",
        "Healthy_test = np.load('/content/drive/MyDrive/DL_Colab/DL_data/Bearing_Healthy_test.npy')\n",
        "InnerFault_test = np.load('/content/drive/MyDrive/DL_Colab/DL_data/Bearing_InnerFault_test.npy')\n",
        "OuterFault_test = np.load('/content/drive/MyDrive/DL_Colab/DL_data/Bearing_OuterFault_test.npy')"
      ],
      "metadata": {
        "id": "b4CMFk_wYu6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (X, y) 만들기: 3 클래스 결합 클래스 인덱스: Healthy=0, Inner=1, Outer=2\n",
        "X_train = np.concatenate([Healthy_train, InnerFault_train, OuterFault_train], axis=0)\n",
        "y_train = np.concatenate([\n",
        "    np.zeros(len(Healthy_train), dtype=np.int64),\n",
        "    np.ones(len(InnerFault_train), dtype=np.int64),\n",
        "    np.full(len(OuterFault_train), 2, dtype=np.int64)\n",
        "], axis=0)\n",
        "\n",
        "X_test = np.concatenate([Healthy_test, InnerFault_test, OuterFault_test], axis=0)\n",
        "y_test = np.concatenate([\n",
        "    np.zeros(len(Healthy_test), dtype=np.int64),\n",
        "    np.ones(len(InnerFault_test), dtype=np.int64),\n",
        "    np.full(len(OuterFault_test), 2, dtype=np.int64)\n",
        "], axis=0)\n",
        "\n",
        "print(\"\\nCombined:\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test :\", X_test.shape,  \"y_test :\", y_test.shape)\n",
        "\n",
        "# 3) LSTM 입력 형태 맞추기\n",
        "# 케이스 A) (N, T)  -> (N, T, 1)\n",
        "# 케이스 B) (N, T, C) -> 그대로 사용\n",
        "# 케이스 C) (T,) 단일 신호면 -> (1, T, 1)로 바꾸고 추가 전처리 필요\n",
        "def ensure_3d(X):\n",
        "    if X.ndim == 2:\n",
        "        return X[..., np.newaxis]\n",
        "    if X.ndim == 3:\n",
        "        return X\n",
        "    raise ValueError(f\"Unexpected input shape: {X.shape}. Expected 2D or 3D array.\")\n",
        "\n",
        "X_train = ensure_3d(X_train)\n",
        "X_test  = ensure_3d(X_test)\n",
        "\n",
        "print(\"\\nAfter ensure_3d:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"X_test :\", X_test.shape)\n",
        "\n",
        "# 4) 정규화\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test  = X_test.astype(np.float32)\n",
        "\n",
        "# feature 차원별 평균/표준편차 (마지막 축=features 기준)\n",
        "# axis=(0,1)은 batch와 timesteps 전체에 대해 통계\n",
        "mean = X_train.mean(axis=(0,1), keepdims=True)\n",
        "std  = X_train.std(axis=(0,1), keepdims=True) + 1e-8\n",
        "\n",
        "X_train = (X_train - mean) / std\n",
        "X_test  = (X_test - mean) / std\n",
        "\n",
        "print(\"\\nNormalization done.\")\n",
        "print(\"train min/max:\", float(X_train.min()), float(X_train.max()))\n",
        "\n",
        "# 5) Train/Validation 분리 + 셔플\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 인덱스 섞기\n",
        "idx = np.random.permutation(len(X_train))\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "# 검증셋 분리\n",
        "val_ratio = 0.2\n",
        "val_size = int(len(X_train) * val_ratio)\n",
        "\n",
        "X_val = X_train[:val_size]\n",
        "y_val = y_train[:val_size]\n",
        "X_tr  = X_train[val_size:]\n",
        "y_tr  = y_train[val_size:]\n",
        "\n",
        "print(\"\\nSplit:\")\n",
        "print(\"X_tr :\", X_tr.shape, \"y_tr :\", y_tr.shape)\n",
        "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
        "\n",
        "# tf.data로 배치 구성\n",
        "batch_size = 64\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_tr, y_tr)).shuffle(2000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds   = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# LSTM 모델 설계\n",
        "timesteps = X_train.shape[1]\n",
        "features  = X_train.shape[2]\n",
        "num_classes = 3\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(timesteps, features)),\n",
        "\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),# 시계열 특징 추출(1)\n",
        "    tf.keras.layers.Dropout(0.3),# 과적합 방지\n",
        "\n",
        "    tf.keras.layers.LSTM(64),# 시계열 특징 추출(2) (마지막 hidden만)\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),# 분류를 위한 dense\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')# 3-class 출력\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),# Adam 최적화\n",
        "    loss='sparse_categorical_crossentropy',# 정수 라벨(0/1/2)이라 sparse 사용\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 7) 학습 (EarlyStopping + Best 모델 저장)\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', patience=5, restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 8) 학습 곡선 시각화\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()\n",
        "\n",
        "# 9) 테스트 평가\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=0)\n",
        "print(f\"\\nTest loss: {test_loss:.4f}\")\n",
        "print(f\"Test acc : {test_acc:.4f}\")\n",
        "\n",
        "# 테스트 예측\n",
        "y_prob = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "# confusion matrix 계산\n",
        "cm = tf.math.confusion_matrix(y_test, y_pred, num_classes=num_classes).numpy()\n",
        "\n",
        "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
        "print(cm)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(cm)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0,1,2], [\"Healthy\",\"Inner\",\"Outer\"])\n",
        "plt.yticks([0,1,2], [\"Healthy\",\"Inner\",\"Outer\"])\n",
        "for i in range(num_classes):\n",
        "    for j in range(num_classes):\n",
        "        plt.text(j, i, cm[i,j], ha='center', va='center')\n",
        "plt.show()\n",
        "\n",
        "# 11) 샘플 몇 개 확인 (예측 결과 출력)\n",
        "class_names = [\"Healthy\", \"InnerFault\", \"OuterFault\"]\n",
        "\n",
        "print(\"\\nSample predictions:\")\n",
        "for i in range(10):\n",
        "    print(f\"True={class_names[int(y_test[i])]}  Pred={class_names[int(y_pred[i])]}\")"
      ],
      "metadata": {
        "id": "v49EiYRqYvWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}